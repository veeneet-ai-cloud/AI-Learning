{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0f1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e4df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f205c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbf1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#print(torch.__version__)\n",
    "#print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40722860",
   "metadata": {},
   "outputs": [],
   "source": [
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path = Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb88c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fc320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e5f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09866b76",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "104da079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb9af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27119467",
   "metadata": {},
   "source": [
    "We'll need to replace the missing values with something. It doesn't generally matter too much what we choose. We'll use the most common value (the \"mode\"). We can use the mode function for that. One wrinkle is that it returns more than one row in the case of ties, so we just grab the first row with iloc[0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f308aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Abbing, Mr. Anthony</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1601</td>\n",
       "      <td>8.05</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbott, Mr. Rossmore Edward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbott, Mrs. Stanton (Rosa Hunt)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abelson, Mr. Samuel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de Mulder, Mr. Theodore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de Pelsmaeker, Mr. Alfons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>del Carlo, Mr. Sebastiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>van Billiard, Mr. Austin Blyler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                   Name   Sex   Age  SibSp  Parch    Ticket  Fare        Cabin Embarked\n",
       "0              1       0.0     3.0                    Abbing, Mr. Anthony  male  24.0    0.0    0.0      1601  8.05      B96 B98        S\n",
       "1              2       NaN     NaN            Abbott, Mr. Rossmore Edward   NaN   NaN    NaN    NaN    347082   NaN  C23 C25 C27      NaN\n",
       "2              3       NaN     NaN       Abbott, Mrs. Stanton (Rosa Hunt)   NaN   NaN    NaN    NaN  CA. 2343   NaN           G6      NaN\n",
       "3              4       NaN     NaN                    Abelson, Mr. Samuel   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "4              5       NaN     NaN  Abelson, Mrs. Samuel (Hannah Wizosky)   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "..           ...       ...     ...                                    ...   ...   ...    ...    ...       ...   ...          ...      ...\n",
       "886          887       NaN     NaN                de Mulder, Mr. Theodore   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "887          888       NaN     NaN              de Pelsmaeker, Mr. Alfons   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "888          889       NaN     NaN              del Carlo, Mr. Sebastiano   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "889          890       NaN     NaN        van Billiard, Mr. Austin Blyler   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "890          891       NaN     NaN            van Melkebeke, Mr. Philemon   NaN   NaN    NaN    NaN       NaN   NaN          NaN      NaN\n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46a6b319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff33325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87785352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318a48f",
   "metadata": {},
   "source": [
    "Here's how we get a quick summary of all the numeric columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70128528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "649c8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e58bba",
   "metadata": {},
   "source": [
    "We can see that Fare contains mainly values of around 0 to 30, but there's a few really big ones. This is very common with fields contain monetary values, and it can cause problems for our model, because once that column is multiplied by a coefficient later, the few rows with really big values will dominate the result.\n",
    "\n",
    "You can see the issue most clearly visually by looking at a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede99a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKJNJREFUeJzt3Qt0FOX9//FvFnIhQBKDJgFJAq0XiFyCoBAvPy2ERKQUJMeqf4pRc/AUgQpp0cYCElBDqQUvBewFCR6lVKygYMCEoFAlEIilhUQjWCpUSOKlIUDKksv8z/PUXbMBtJEd9tnN+3XOONmZ2d3Z7ybrh+cyG2RZliUAAAAGcfj6BAAAAFojoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjNNR/FBzc7McOXJEunbtKkFBQb4+HQAA8D9Q14Y9fvy49OjRQxwOR+AFFBVO4uPjfX0aAADgWzh8+LD07Nkz8AKKajlxvcCIiAivPnZDQ4MUFhZKWlqaBAcHe/WxQX3tRn3tRX3tRX0Dv751dXW6gcH1//GACyiubh0VTuwIKOHh4fpx+QPxPuprL+prL+prL+rbfuob9D8Mz2CQLAAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxOvr6BEzVb+6b4mz65q+DNsU/F4z29SkAAOA1tKAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgH8HlF69eklQUNAZy5QpU/T+U6dO6Z+7desmXbp0kYyMDKmurvZ4jEOHDsno0aMlPDxcYmJiZObMmdLY2OjdVwUAANpPQNm1a5ccPXrUvRQVFentt99+u17PmDFD1q9fL2vWrJGtW7fKkSNHZPz48e77NzU16XBy+vRp2b59u6xcuVLy8/Nlzpw53n5dAACgvQSUSy65ROLi4tzLhg0b5Lvf/a7cdNNNcuzYMVm+fLksWrRIhg8fLoMHD5YVK1boILJjxw59/8LCQqmoqJAXX3xRkpOTZdSoUTJ//nxZsmSJDi0AAADnNQZFBQoVNO677z7dzVNWViYNDQ2SmprqPqZPnz6SkJAgJSUl+rZa9+/fX2JjY93HpKenS11dnZSXl/OOAAAAraN8S+vWrZPa2lq555579O2qqioJCQmRqKgoj+NUGFH7XMe0DCeu/a595+J0OvXiogKNogKRWrzJ9XihDkv8ibfrYPd5+sv5+hvqay/qay/qG/j1bWjDc3/rgKK6c1QXTY8ePcRueXl5kpube8Z21WWkBtvaYf6QZvEnBQUF4k9c45dgD+prL+prL+prL1/Wt76+3t6A8vHHH8vmzZvl1VdfdW9TY1JUt49qVWnZiqJm8ah9rmNKS0s9Hss1y8d1zNnk5ORIdna2RwtKfHy8pKWlSUREhHg73ak3b/Zuhzibg8Rf7JubLv7AVd+RI0dKcHCwr08n4FBfe1Ffe1HfwK9v3Zc9ILYFFDX4VU0RVjNyXNSgWPWCi4uL9fRipbKyUk8rTklJ0bfV+vHHH5eamhp9f0UVS4WMpKSkcz5faGioXlpTz2dXkVU4cTb5T0Dxtz9mO987UF+7UV97UV97+bK+bXneNgeU5uZmHVAyMzOlY8ev7h4ZGSlZWVm6pSM6OlqHjmnTpulQMmzYMH2MavFQQWTixImycOFCPe5k1qxZ+topZwsgAACgfWpzQFFdO6pVRM3eaW3x4sXicDh0C4oa1Kpm6CxdutS9v0OHDnpq8uTJk3Vw6dy5sw468+bNO/9XAgAA2m9AUa0glnX2GS5hYWH6miZqOZfExES/G9AJAAAuLL6LBwAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMD/A8onn3wiP/rRj6Rbt27SqVMn6d+/v+zevdu937IsmTNnjnTv3l3vT01Nlf3793s8xhdffCETJkyQiIgIiYqKkqysLDlx4oR3XhEAAGhfAeXf//63XH/99RIcHCwbN26UiooK+fWvfy0XXXSR+5iFCxfKM888I88995zs3LlTOnfuLOnp6XLq1Cn3MSqclJeXS1FRkWzYsEG2bdsm999/v3dfGQAA8Fsd23LwL3/5S4mPj5cVK1a4t/Xu3duj9eSpp56SWbNmydixY/W2F154QWJjY2XdunVy5513yvvvvy+bNm2SXbt2yZAhQ/Qxzz77rNx6663y5JNPSo8ePbz36gAAQOAHlNdff123htx+++2ydetWufTSS+WBBx6QSZMm6f0HDx6Uqqoq3a3jEhkZKUOHDpWSkhIdUNRadeu4womijnc4HLrF5bbbbjvjeZ1Op15c6urq9LqhoUEv3uR6vFCHJf7E23Ww+zz95Xz9DfW1F/W1F/UN/Po2tOG52xRQ/vGPf8iyZcskOztbHnnkEd0K8pOf/ERCQkIkMzNThxNFtZi0pG679ql1TEyM50l07CjR0dHuY1rLy8uT3NzcM7YXFhZKeHi42GH+kGbxJwUFBeJPVPce7EN97UV97UV97eXL+tbX19sTUJqbm3XLxxNPPKFvDxo0SPbt26fHm6iAYpecnBwdilq2oKiuprS0ND3Q1tvpTr15s3c7xNkcJP5i39x08Qeu+o4cOVKPZYJ3UV97UV97Ud/Ar2/dlz0gXg8oamZOUlKSx7a+ffvKn//8Z/1zXFycXldXV+tjXdTt5ORk9zE1NTUej9HY2Khn9rju31poaKheWlMFtqvIKpw4m/wnoPjbH7Od7x2or92or72or718Wd+2PG+bZvGoGTyVlZUe2z788ENJTEx0D5hVIaO4uNgjLamxJSkpKfq2WtfW1kpZWZn7mC1btujWGTVWBQAAoE0tKDNmzJDrrrtOd/H88Ic/lNLSUvnd736nFyUoKEimT58ujz32mFx++eU6sMyePVvPzBk3bpy7xeWWW27RA2tV15Bqcpo6daoeQMsMHgAA0OaAcs0118jatWv1mJB58+bpAKKmFavrmrg89NBDcvLkSX1dE9VScsMNN+hpxWFhYe5jXnrpJR1KRowYoWfvZGRk6GunAAAAtDmgKN///vf1ci6qFUWFF7Wci5qxs2rVKt4BAABwVnwXDwAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAAD/Dihz586VoKAgj6VPnz7u/adOnZIpU6ZIt27dpEuXLpKRkSHV1dUej3Ho0CEZPXq0hIeHS0xMjMycOVMaGxu994oAAIDf69jWO1x11VWyefPmrx6g41cPMWPGDHnjjTdkzZo1EhkZKVOnTpXx48fLu+++q/c3NTXpcBIXFyfbt2+Xo0ePyt133y3BwcHyxBNPeOs1AQCA9hZQVCBRAaO1Y8eOyfLly2XVqlUyfPhwvW3FihXSt29f2bFjhwwbNkwKCwuloqJCB5zY2FhJTk6W+fPny8MPP6xbZ0JCQrzzqgAAQPsKKPv375cePXpIWFiYpKSkSF5eniQkJEhZWZk0NDRIamqq+1jV/aP2lZSU6ICi1v3799fhxCU9PV0mT54s5eXlMmjQoLM+p9Pp1ItLXV2dXqvnU4s3uR4v1GGJP/F2Hew+T385X39Dfe1Ffe1FfQO/vg1teO42BZShQ4dKfn6+XHnllbp7Jjc3V2688UbZt2+fVFVV6RaQqKgoj/uoMKL2KWrdMpy49rv2nYsKQeq5WlMtMmosix3mD2kWf1JQUCD+pKioyNenENCor72or72or718Wd/6+np7AsqoUaPcPw8YMEAHlsTERHn55ZelU6dOYpecnBzJzs72aEGJj4+XtLQ0iYiI8Hq6U2/e7N0OcTYHib/YNzdd/IGrviNHjtRjj+Bd1Nde1Nde1Dfw61v3ZQ+ILV08LanWkiuuuEIOHDigX/Dp06eltrbWoxVFzeJxjVlR69LSUo/HcM3yOdu4FpfQ0FC9tKYKbFeRVThxNvlPQPG3P2Y73ztQX7tRX3tRX3v5sr5ted7zug7KiRMn5KOPPpLu3bvL4MGD9RMXFxe791dWVuppxWqsiqLWe/fulZqaGvcxKs2pVpCkpKTzORUAABBA2tSC8rOf/UzGjBmju3WOHDkijz76qHTo0EHuuusuPa04KytLd8VER0fr0DFt2jQdStQAWUV1yaggMnHiRFm4cKEedzJr1ix97ZSztZAAAID2qU0B5V//+pcOI59//rlccsklcsMNN+gpxOpnZfHixeJwOPQF2tSsGzVDZ+nSpe77qzCzYcMGPWtHBZfOnTtLZmamzJs3z/uvDAAAtI+Asnr16q/dr6YeL1myRC/nolpf/G3GCQAAuLD4Lh4AAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAgRVQFixYIEFBQTJ9+nT3tlOnTsmUKVOkW7du0qVLF8nIyJDq6mqP+x06dEhGjx4t4eHhEhMTIzNnzpTGxsbzORUAABBAvnVA2bVrl/z2t7+VAQMGeGyfMWOGrF+/XtasWSNbt26VI0eOyPjx4937m5qadDg5ffq0bN++XVauXCn5+fkyZ86c83slAACgfQeUEydOyIQJE+T3v/+9XHTRRe7tx44dk+XLl8uiRYtk+PDhMnjwYFmxYoUOIjt27NDHFBYWSkVFhbz44ouSnJwso0aNkvnz58uSJUt0aAEAAOj4be6kunBUK0hqaqo89thj7u1lZWXS0NCgt7v06dNHEhISpKSkRIYNG6bX/fv3l9jYWPcx6enpMnnyZCkvL5dBgwad8XxOp1MvLnV1dXqtnkst3uR6vFCHJf7E23Ww+zz95Xz9DfW1F/W1F/UN/Po2tOG52xxQVq9eLe+9957u4mmtqqpKQkJCJCoqymO7CiNqn+uYluHEtd+172zy8vIkNzf3jO2qNUaNY7HD/CHN4k8KCgrEnxQVFfn6FAIa9bUX9bUX9bWXL+tbX19vT0A5fPiwPPjgg/rFhYWFyYWSk5Mj2dnZHi0o8fHxkpaWJhEREV5Pd+r1zd7tEGdzkPiLfXPTxR+46jty5EgJDg729ekEHOprL+prL+ob+PWt+7IHxOsBRXXh1NTUyNVXX+0x6HXbtm3ym9/8Rt588009jqS2ttajFUXN4omLi9M/q3VpaanH47pm+biOaS00NFQvrakC21VkFU6cTf4TUPztj9nO9w7U127U117U116+rG9bnrdNg2RHjBghe/fulT179riXIUOG6AGzrp/VkxcXF7vvU1lZqacVp6Sk6NtqrR5DBR0XlehUS0hSUlJbTgcAAASoNrWgdO3aVfr16+exrXPnzvqaJ67tWVlZujsmOjpah45p06bpUKIGyCqqW0YFkYkTJ8rChQv1uJNZs2bpgbdnayUBAADtz7eaxfN1Fi9eLA6HQ1+gTc28UTN0li5d6t7foUMH2bBhg561o4KLCjiZmZkyb948b58KAABorwHl7bff9ritBs+qa5qo5VwSExP9btYJAAC4cPguHgAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAAD+HVCWLVsmAwYMkIiICL2kpKTIxo0b3ftPnTolU6ZMkW7dukmXLl0kIyNDqqurPR7j0KFDMnr0aAkPD5eYmBiZOXOmNDY2eu8VAQCA9hVQevbsKQsWLJCysjLZvXu3DB8+XMaOHSvl5eV6/4wZM2T9+vWyZs0a2bp1qxw5ckTGjx/vvn9TU5MOJ6dPn5bt27fLypUrJT8/X+bMmeP9VwYAAPxWx7YcPGbMGI/bjz/+uG5V2bFjhw4vy5cvl1WrVungoqxYsUL69u2r9w8bNkwKCwuloqJCNm/eLLGxsZKcnCzz58+Xhx9+WObOnSshISHefXUAACDwA0pLqjVEtZScPHlSd/WoVpWGhgZJTU11H9OnTx9JSEiQkpISHVDUun///jqcuKSnp8vkyZN1K8ygQYPO+lxOp1MvLnV1dXqtnk8t3uR6vFCHJf7E23Ww+zz95Xz9DfW1F/W1F/UN/Po2tOG52xxQ9u7dqwOJGm+ixpmsXbtWkpKSZM+ePboFJCoqyuN4FUaqqqr0z2rdMpy49rv2nUteXp7k5uaesV21yKixLHaYP6RZ/ElBQYH4k6KiIl+fQkCjvvaivvaivvbyZX3r6+vtCyhXXnmlDiPHjh2TV155RTIzM/V4Ezvl5ORIdna2RwtKfHy8pKWl6cG63k536s2bvdshzuYg8Rf75qaLP3DVd+TIkRIcHOzr0wk41Nde1Nde1Dfw61v3ZQ+ILQFFtZJcdtll+ufBgwfLrl275Omnn5Y77rhDD36tra31aEVRs3ji4uL0z2pdWlrq8XiuWT6uY84mNDRUL62pAttVZBVOnE3+E1D87Y/ZzvcO1Ndu1Nde1NdevqxvW573vK+D0tzcrMeHqLCinri4uNi9r7KyUk8rVl1CilqrLqKamhr3MSrNqVYQ1U0EAADQ5hYU1dUyatQoPfD1+PHjesbO22+/LW+++aZERkZKVlaW7oqJjo7WoWPatGk6lKgBsorqklFBZOLEibJw4UI97mTWrFn62ilnayEBAADtU5sCimr5uPvuu+Xo0aM6kKiLtqlwovqzlMWLF4vD4dAXaFOtKmqGztKlS93379Chg2zYsEHP2lHBpXPnznoMy7x587z/ygAAQPsIKOo6J18nLCxMlixZopdzSUxM9LsZJwAA4MLiu3gAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAA+HdAycvLk2uuuUa6du0qMTExMm7cOKmsrPQ45tSpUzJlyhTp1q2bdOnSRTIyMqS6utrjmEOHDsno0aMlPDxcP87MmTOlsbHRO68IAAC0r4CydetWHT527NghRUVF0tDQIGlpaXLy5En3MTNmzJD169fLmjVr9PFHjhyR8ePHu/c3NTXpcHL69GnZvn27rFy5UvLz82XOnDnefWUAAMBvdWzLwZs2bfK4rYKFagEpKyuT//u//5Njx47J8uXLZdWqVTJ8+HB9zIoVK6Rv37461AwbNkwKCwuloqJCNm/eLLGxsZKcnCzz58+Xhx9+WObOnSshISHefYUAACCwA0prKpAo0dHReq2CimpVSU1NdR/Tp08fSUhIkJKSEh1Q1Lp///46nLikp6fL5MmTpby8XAYNGnTG8zidTr241NXV6bV6LrV4k+vxQh2W+BNv18Hu8/SX8/U31Nde1Nde1Dfw69vQhuf+1gGlublZpk+fLtdff73069dPb6uqqtItIFFRUR7HqjCi9rmOaRlOXPtd+8419iU3N/eM7ao1Ro1jscP8Ic3iTwoKCsSfqC5C2If62ov62ov62suX9a2vr7c/oKixKPv27ZN33nlH7JaTkyPZ2dkeLSjx8fF6/EtERITX051682bvdoizOUj8xb656eIPXPUdOXKkBAcH+/p0Ag71tRf1tRf1Dfz61n3ZA2JbQJk6daps2LBBtm3bJj179nRvj4uL04Nfa2trPVpR1Cwetc91TGlpqcfjuWb5uI5pLTQ0VC+tqQLbVWQVTpxN/hNQ/O2P2c73DtTXbtTXXtTXXr6sb1uet02zeCzL0uFk7dq1smXLFundu7fH/sGDB+snLy4udm9T05DVtOKUlBR9W6337t0rNTU17mNUolMtIUlJSW05HQAAEKA6trVbR83Qee211/S1UFxjRiIjI6VTp056nZWVpbtj1MBZFTqmTZumQ4kaIKuobhkVRCZOnCgLFy7UjzFr1iz92GdrJQEAAO1PmwLKsmXL9Prmm2/22K6mEt9zzz3658WLF4vD4dAXaFMzb9QMnaVLl7qP7dChg+4eUrN2VHDp3LmzZGZmyrx587zzigAAQPsKKKqL55uEhYXJkiVL9HIuiYmJfjfrBAAAXDh8Fw8AADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA/w8o27ZtkzFjxkiPHj0kKChI1q1b57HfsiyZM2eOdO/eXTp16iSpqamyf/9+j2O++OILmTBhgkREREhUVJRkZWXJiRMnzv/VAACAgNCxrXc4efKkDBw4UO677z4ZP378GfsXLlwozzzzjKxcuVJ69+4ts2fPlvT0dKmoqJCwsDB9jAonR48elaKiImloaJB7771X7r//flm1apV3XlU71Ovnb4g/CO1gycJrRfrNfVMqH/++r08HABAoAWXUqFF6ORvVevLUU0/JrFmzZOzYsXrbCy+8ILGxsbql5c4775T3339fNm3aJLt27ZIhQ4boY5599lm59dZb5cknn9QtMwAAoH1rc0D5OgcPHpSqqirdreMSGRkpQ4cOlZKSEh1Q1Fp167jCiaKOdzgcsnPnTrntttvOeFyn06kXl7q6Or1WrS9q8SbX44U6LK8+LsSjrmrt7fcOX/3+Ult7UF97Ud/Ar29DG57bqwFFhRNFtZi0pG679ql1TEyM50l07CjR0dHuY1rLy8uT3NzcM7YXFhZKeHi42GH+kGZbHhdf1begoMDXpxGwVPcp7EN97UV97eXL+tbX1/smoNglJydHsrOzPVpQ4uPjJS0tTQ+09Xa6U2/e7N0OcTYHefWx8d+WExVOVH3L5tzi69MJOK7f35EjR0pwcLCvTyfgUF97Ud/Ar2/dlz0gFzygxMXF6XV1dbWexeOibicnJ7uPqamp8bhfY2Ojntnjun9roaGhemlNFdiuIqtw4mwioNhF1ZcPIPvY+bcB6ms36msvX9a3Lc/r1eugqFk7KmQUFxd7pCU1tiQlJUXfVuva2lopKytzH7NlyxZpbm7WY1UAAADa3IKirldy4MABj4Gxe/bs0WNIEhISZPr06fLYY4/J5Zdf7p5mrGbmjBs3Th/ft29fueWWW2TSpEny3HPP6SanqVOn6gG0zOABAADfKqDs3r1bvve977lvu8aGZGZmSn5+vjz00EP6WinquiaqpeSGG27Q04pd10BRXnrpJR1KRowYoWfvZGRk6GunAAAAfKuAcvPNN+vrnZyLurrsvHnz9HIuqrWFi7IBAIBz4bt4AACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOB19fQJov3r9/A3xN/9cMNrXpwAA7QItKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOFxJFghwXLEXgD/yaQvKkiVLpFevXhIWFiZDhw6V0tJSX54OAABo7y0of/rTnyQ7O1uee+45HU6eeuopSU9Pl8rKSomJifHVaQEwgKmtPqEdLFl4rUi/uW+KsynIYx+tPkCAtKAsWrRIJk2aJPfee68kJSXpoBIeHi7PP/+8r04JAAC05xaU06dPS1lZmeTk5Li3ORwOSU1NlZKSkjOOdzqdenE5duyYXn/xxRfS0NDg1XNTj1dfXy8dGxzS1Oz5LyScv47NltTXN/ttfS/72ctislCHJbMGNUvyL14V55f1ZaDZhfn9/fzzz312XoHC9fmrahkcHCyBYmhesZj6+fB1duaMEG87fvy4XluW9Y3H+uSz67PPPpOmpiaJjY312K5uf/DBB2ccn5eXJ7m5uWds7927t63nCXv8P1+fQICjvr6p78W/vsAnAtj8+WDn77QKKpGRkV97jF/840q1tKjxKi7Nzc269aRbt24SFOTdf4XX1dVJfHy8HD58WCIiIrz62KC+dqO+9qK+9qK+gV9fy7J0OOnRo8c3HuuTgHLxxRdLhw4dpLq62mO7uh0XF3fG8aGhoXppKSoqytZzVG8efyD2ob72or72or72or728nV9v6nlxKeDZENCQmTw4MFSXFzs0SqibqekpPjilAAAgEF81sWjumwyMzNlyJAhcu211+ppxidPntSzegAAQPvms4Byxx13yKeffipz5syRqqoqSU5Olk2bNp0xcPZCU11Jjz766BldSvAO6msv6msv6msv6muvUD+rb5D1v8z1AQAAuID4skAAAGAcAgoAADAOAQUAABiHgAIAAIxDQGlhyZIl0qtXLwkLC9PfsFxaWurrU/IL27ZtkzFjxugrA6or+65bt85jvxqHrWZrde/eXTp16qS/c2n//v0ex6grA0+YMEFfPEhdhC8rK0tOnDhxgV+JmdRXPVxzzTXStWtX/U3f48aN09/63dKpU6dkypQp+urKXbp0kYyMjDMuhHjo0CEZPXq0/lJO9TgzZ86UxsZGae+WLVsmAwYMcF+8Sl2LaePGje791NZ7FixYoD8jpk+f7t5Gfc/P3LlzdU1bLn369AmM+qpZPLCs1atXWyEhIdbzzz9vlZeXW5MmTbKioqKs6upqX5+a8QoKCqxf/OIX1quvvqpmhFlr16712L9gwQIrMjLSWrdunfW3v/3N+sEPfmD17t3b+s9//uM+5pZbbrEGDhxo7dixw/rLX/5iXXbZZdZdd93lg1djnvT0dGvFihXWvn37rD179li33nqrlZCQYJ04ccJ9zI9//GMrPj7eKi4utnbv3m0NGzbMuu6669z7GxsbrX79+lmpqanWX//6V/2eXXzxxVZOTo7V3r3++uvWG2+8YX344YdWZWWl9cgjj1jBwcG63gq19Y7S0lKrV69e1oABA6wHH3zQvZ36np9HH33Uuuqqq6yjR4+6l08//TQg6ktA+dK1115rTZkyxX27qanJ6tGjh5WXl+fT8/I3rQNKc3OzFRcXZ/3qV79yb6utrbVCQ0OtP/7xj/p2RUWFvt+uXbvcx2zcuNEKCgqyPvnkkwv8CsxXU1Oj67V161Z3PdX/UNesWeM+5v3339fHlJSU6NvqQ8fhcFhVVVXuY5YtW2ZFRERYTqfTB6/CbBdddJH1hz/8gdp6yfHjx63LL7/cKioqsm666SZ3QKG+3gkoAwcOPOs+f68vXTwicvr0aSkrK9NdDy4Oh0PfLikp8em5+buDBw/qC/G1rK36HgbVheaqrVqrbh11VWEXdbx6D3bu3OmT8zbZsWPH9Do6Olqv1e+u+pr6ljVWTbwJCQkeNe7fv7/HhRDT09P1l4eVl5df8NdgKvUt66tXr9ZXtVZdPdTWO1QXg+pCaFlHhfp6x/79+3UX+3e+8x3dVa66bAKhvn7xbcZ2++yzz/QHU+ur2KrbH3zwgc/OKxCocKKcrbaufWqt+j1b6tixo/4fsOsYfPWdVar//vrrr5d+/frpbapG6vutWn+BZusan+09cO1r7/bu3asDieqvV/30a9eulaSkJNmzZw+1PU8q8L333nuya9euM/bxu3v+hg4dKvn5+XLllVfK0aNHJTc3V2688UbZt2+f39eXgAL42b9E1QfPO++84+tTCSjqw12FEdU69corr+jvCdu6dauvT8vvHT58WB588EEpKirSkw/gfaNGjXL/rAZ7q8CSmJgoL7/8sp6U4M/o4hGRiy++WDp06HDGyGZ1Oy4uzmfnFQhc9fu62qp1TU2Nx341glzN7KH+X5k6daps2LBB3nrrLenZs6d7u6qR6qasra392hqf7T1w7Wvv1L8yL7vsMv0t62rW1MCBA+Xpp5+mtudJdTGov+2rr75at4qqRQW/Z555Rv+s/qVOfb0rKipKrrjiCjlw4IDf//4SUL78cFIfTMXFxR5N6eq2avbFt9e7d2/9S96ytqpvU40tcdVWrdUfkPowc9myZYt+D9S/Bto7NfZYhRPV7aDqomrakvrdDQ4O9qixmoas+qFb1lh1Y7QMgupftWparerKgCf1u+d0OqnteRoxYoSujWqdci1qrJkaJ+H6mfp614kTJ+Sjjz7Sl3Xw+99fnw7RNWyasZpZkp+fr2eV3H///XqaccuRzTj3CH01PU0t6ldq0aJF+uePP/7YPc1Y1fK1116z/v73v1tjx4496zTjQYMGWTt37rTeeecdPeKfacb/NXnyZD1N++233/aYSlhfX+8xlVBNPd6yZYueSpiSkqKX1lMJ09LS9FTlTZs2WZdccokRUwl97ec//7meEXXw4EH9+6luqxlkhYWFej+19a6Ws3gU6nt+fvrTn+rPBvX7++677+rpwmqasJrt5+/1JaC08Oyzz+o3Ul0PRU07VtfkwDd76623dDBpvWRmZrqnGs+ePduKjY3VIXDEiBH6ehMtff755zqQdOnSRU9vu/fee3XwwX+nbp9tUddGcVFh74EHHtDTY8PDw63bbrtNh5iW/vnPf1qjRo2yOnXqpD/A1AdbQ0OD1d7dd999VmJiov67Vx/M6vfTFU4UamtvQKG+5+eOO+6wunfvrn9/L730Un37wIEDAVHfIPUf37bhAAAAeGIMCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAABimv8PbW6zqxSk9e8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['Fare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d745540",
   "metadata": {},
   "source": [
    "To fix this, the most common approach is to take the logarithm, which squishes the big numbers and makes the distribution more reasonable. Note, however, that there are zeros in the Fare column, and log(0) is infinite -- to fix this, we'll simply add 1 to all values first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3573d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf7d39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c33055",
   "metadata": {},
   "source": [
    "It looks from the describe() output like Pclass contains just 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70811f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(1), np.int64(2), np.int64(3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5facabc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1e066",
   "metadata": {},
   "source": [
    "Clearly we can't multiply strings like male or S by coefficients, so we need to replace those with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02e1d5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5373c2",
   "metadata": {},
   "source": [
    "We can see that 5 columns have been added to the end\n",
    "Here's what the first few rows of those newly added columns look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ae1fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n",
       "0         1           0         0         0         1           0           0           1\n",
       "1         0           1         1         0         0           1           0           0\n",
       "2         0           1         0         0         1           0           0           1\n",
       "3         0           1         1         0         0           0           0           1\n",
       "4         1           0         0         0         1           0           0           1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "df[added_cols] = df[added_cols].astype(int)\n",
    "df[added_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ec498",
   "metadata": {},
   "source": [
    "Now we can create our independent (predictors) and dependent (target) variables. They both need to be PyTorch tensors. Our dependent variable is Survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71aac249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115d3bb",
   "metadata": {},
   "source": [
    "Our independent variables are all the continuous variables of interest plus all the dummy variables we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4263c04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n",
    "\n",
    "t_indep = tensor(df[indep_cols].values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f91d5b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d737106",
   "metadata": {},
   "source": [
    "Setting up a linear model\n",
    "\n",
    "Now that we've got a matrix of independent variables and a dependent variable vector, we can work on calculating our predictions and our loss. In this section, we're going to manually do a single step of calculating predictions and loss for every row of our data.\n",
    "\n",
    "Our first model will be a simple linear model. \n",
    "\n",
    "We'll need a coefficient for each column in t_indep. We'll pick random numbers in the range (-0.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b7bf71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(442)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb69a15",
   "metadata": {},
   "source": [
    "Our predictions will be calculated by multiplying each row by the coefficients, and adding them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d038babd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n",
       "        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n",
       "        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        ...,\n",
       "        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n",
       "        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n",
       "        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07cf8b",
   "metadata": {},
   "source": [
    "We can see we've got a problem here. The sums of each row will be dominated by the first column, which is Age, since that's bigger on average than all the others.\n",
    "\n",
    "Let's make all the columns contain numbers from 0 to 1, by dividing each column by its max():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "360afb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6ca2bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        ...,\n",
       "        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafaf773",
   "metadata": {},
   "source": [
    "We can now create predictions from our linear model, by adding up the rows of the product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07f3823a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6b481",
   "metadata": {},
   "source": [
    "Of course, these predictions aren't going to be any use, since our coefficients are random -- they're just a starting point for our gradient descent process.\n",
    "\n",
    "To do gradient descent, we need a loss function. Taking the average error of the rows (i.e. the absolute value of the difference between the prediction and the dependent) is generally a reasonable approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8d15c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacfeb3",
   "metadata": {},
   "source": [
    "Now that we've tested out a way of calculating predictions, and loss, let's pop them into functions to make life easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cbd1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638ef90",
   "metadata": {},
   "source": [
    "Doing a gradient descent step\n",
    "\n",
    "In this section, we're going to do a single \"epoch\" of gradient descent manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4348a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e06c5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1520ea",
   "metadata": {},
   "source": [
    "Use backward() to ask PyTorch to calculate gradients now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4e2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa9b92",
   "metadata": {},
   "source": [
    "Let's see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2a84054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df6905",
   "metadata": {},
   "source": [
    "Note that each time we call backward, the gradients are actually added to whatever is in the .grad attribute. Let's try running the above steps again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad61f65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d79f86",
   "metadata": {},
   "source": [
    "As you see, our .grad values are have doubled. That's because it added the gradients a second time. For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero.\n",
    "\n",
    "We can now do one gradient descent step, and check that our loss decreases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "559701de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4945)\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    coeffs.sub_(coeffs.grad * 0.1)\n",
    "    coeffs.grad.zero_()\n",
    "    print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de3c94",
   "metadata": {},
   "source": [
    "Training the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69ad86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63c0da",
   "metadata": {},
   "source": [
    " let's use RandomSplitter to get indices that will split our data into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a9f68db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf831042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#713) [np.int64(788),np.int64(525),np.int64(821),np.int64(253),np.int64(374),np.int64(98),np.int64(215),np.int64(313),np.int64(281),np.int64(305),np.int64(701),np.int64(812),np.int64(76),np.int64(50),np.int64(387),np.int64(47),np.int64(516),np.int64(564),np.int64(434),np.int64(117)...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fcbbb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "len(trn_indep),len(val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011b58f",
   "metadata": {},
   "source": [
    "We'll create functions for the three things we did manually above: updating coeffs, doing one full gradient descent step, and initilising coeffs to random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f636313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c81626b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cbb1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed582a9",
   "metadata": {},
   "source": [
    "We can now use these functions to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e1d7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643207f",
   "metadata": {},
   "source": [
    "Let's try it. Our loss will print at the end of every step, so we hope we'll see it going down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9eccda19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(18, lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c14f5",
   "metadata": {},
   "source": [
    "Let's take a look at the coefficients for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0d94a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.2694),\n",
       " 'SibSp': tensor(0.0901),\n",
       " 'Parch': tensor(0.2359),\n",
       " 'LogFare': tensor(0.0280),\n",
       " 'Sex_male': tensor(-0.3990),\n",
       " 'Sex_female': tensor(0.2345),\n",
       " 'Pclass_1': tensor(0.7232),\n",
       " 'Pclass_2': tensor(0.4112),\n",
       " 'Pclass_3': tensor(0.3601),\n",
       " 'Embarked_C': tensor(0.0955),\n",
       " 'Embarked_Q': tensor(0.2395),\n",
       " 'Embarked_S': tensor(0.2122)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe9f1d",
   "metadata": {},
   "source": [
    "Measuring accuracy\n",
    "\n",
    "\n",
    "Let's see how accurate we were on the validation set. First, calculate the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8820620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calc_preds(coeffs, val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c436ac",
   "metadata": {},
   "source": [
    "We'll assume that any passenger with a score of over 0.5 is predicted to survive. So that means we're correct for each row where preds>0.5 is the same as the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "145720ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool()==(preds>0.5)\n",
    "results[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b744f",
   "metadata": {},
   "source": [
    "Let's see what our average accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a06132b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a5aee",
   "metadata": {},
   "source": [
    "Lets ceate a function for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4837ca9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.5)).float().mean()\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7aeda",
   "metadata": {},
   "source": [
    "Using sigmoid\n",
    "\n",
    "Looking at our predictions, there's one obvious problem -- some of our predictions of the probability of survival are >1, and some are <0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0eada16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8160,  0.1295, -0.0148,  0.1831,  0.1520,  0.1350,  0.7279,  0.7754,  0.3222,  0.6740,  0.0753,  0.0389,  0.2216,  0.7631,\n",
       "         0.0678,  0.3997,  0.3324,  0.8278,  0.1078,  0.7126,  0.1023,  0.3627,  0.9937,  0.8050,  0.1153,  0.1455,  0.8652,  0.3425])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c311308",
   "metadata": {},
   "source": [
    "To fix this, we should pass every prediction through the sigmoid function, which has a minimum at zero and maximum at one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4fe1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c12607",
   "metadata": {},
   "source": [
    "Let's train a new model now, using this updated function to calculate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be35f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510; 0.327; 0.294; 0.207; 0.201; 0.199; 0.198; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6697d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90f00dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-1.5061),\n",
       " 'SibSp': tensor(-1.1575),\n",
       " 'Parch': tensor(-0.4267),\n",
       " 'LogFare': tensor(0.2543),\n",
       " 'Sex_male': tensor(-10.3320),\n",
       " 'Sex_female': tensor(8.4185),\n",
       " 'Pclass_1': tensor(3.8389),\n",
       " 'Pclass_2': tensor(2.1398),\n",
       " 'Pclass_3': tensor(-6.2331),\n",
       " 'Embarked_C': tensor(1.4771),\n",
       " 'Embarked_Q': tensor(2.1168),\n",
       " 'Embarked_S': tensor(-4.7958)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31c450",
   "metadata": {},
   "source": [
    "Now that we've got a trained model. Lets test it on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6233ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb566f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Fare'] = tst_df.Fare.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29862bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df.fillna(modes, inplace=True)\n",
    "tst_df['LogFare'] = np.log(tst_df['Fare']+1)\n",
    "tst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "\n",
    "tst_df[added_cols] = tst_df[added_cols].astype(int)\n",
    "\n",
    "tst_indep = tensor(tst_df[indep_cols].values, dtype=torch.float)\n",
    "tst_indep = tst_indep / vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423ec9d",
   "metadata": {},
   "source": [
    "Let's calculate our predictions of which passengers survived in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d649a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Survived'] = (calc_preds(tst_indep, coeffs)>0.5).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff565472",
   "metadata": {},
   "source": [
    "Using matrix product\n",
    "\n",
    "\n",
    "We can make things quite a bit neater...\n",
    "\n",
    "(val_indep*coeffs).sum(axis=1)\n",
    "\n",
    "Multiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the @ operator to indicate matrix products, and is supported by PyTorch tensors. Therefore, we can replicate the above calculate more simply like so:\n",
    "\n",
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b89fafb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n",
       "          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n",
       "         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n",
       "         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n",
       "        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n",
       "        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n",
       "        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n",
       "        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n",
       "        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n",
       "        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n",
       "          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n",
       "        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n",
       "        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n",
       "        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf13c98",
   "metadata": {},
   "source": [
    "Let's use this to replace how calc_preds works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "806d3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336d292",
   "metadata": {},
   "source": [
    "In order to do matrix-matrix products, we need to turn coeffs into a column vector (i.e. a matrix with a single column), which we can do by passing a second argument 1 to torch.rand(), indicating that we want our coefficients to have one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68abccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb123f",
   "metadata": {},
   "source": [
    "We'll also need to turn our dependent variable into a column vector, which we can do by indexing the column dimension with the special value None, which tells PyTorch to add a new dimension in this position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e55b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dep = trn_dep[:,None]\n",
    "val_dep = val_dep[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dbe81e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512; 0.323; 0.290; 0.205; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e10fdb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b271015d",
   "metadata": {},
   "source": [
    "A neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27c6f1",
   "metadata": {},
   "source": [
    "Initializes the learnable parameters for a simple two-layer neural model.\n",
    "The first layer transforms n_coeff input features into n_hidden hidden units.\n",
    "We initialize weights with small random values centered around zero and scaled by n_hidden\n",
    "to maintain stable output magnitudes and gradients.\n",
    "The second layer maps the n_hidden activations to a single output using another weight matrix.\n",
    "A constant bias term is also added to the output.\n",
    "All parameters are marked with requires_grad=True to enable gradient-based optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db06176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b340e",
   "metadata": {},
   "source": [
    "Now we have our coefficients, we can create our neural net. The key steps are the two matrix products, indeps@l1 and res@l2 (where res is the output of the first layer). The first layer output is passed to F.relu (that's our non-linearity), and the second is passed to torch.sigmoid as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10598190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1,l2,const = coeffs\n",
    "    res = F.relu(indeps@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4720d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "049e386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543; 0.532; 0.520; 0.505; 0.487; 0.466; 0.439; 0.407; 0.373; 0.343; 0.319; 0.301; 0.286; 0.274; 0.264; 0.256; 0.250; 0.245; 0.240; 0.237; 0.234; 0.231; 0.229; 0.227; 0.226; 0.224; 0.223; 0.222; 0.221; 0.220; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30e4c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543; 0.400; 0.260; 0.390; 0.221; 0.211; 0.197; 0.195; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a74c2e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912d5cf",
   "metadata": {},
   "source": [
    "Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9298ec",
   "metadata": {},
   "source": [
    "The neural net in the previous section only uses one hidden layer, so it doesn't count as \"deep\" learning. But we can use the exact same technique to make our neural net deep, by adding more matrix multiplications.\n",
    "\n",
    "First, we'll need to create additional coefficients for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3381d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n",
    "    sizes = [n_coeff] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23833938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i,l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.relu(res)\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "882f6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    layers,consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "787a4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521; 0.483; 0.427; 0.379; 0.379; 0.379; 0.379; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.377; 0.376; 0.371; 0.333; 0.239; 0.224; 0.208; 0.204; 0.203; 0.203; 0.207; 0.197; 0.196; 0.195; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "440e39f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03196477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
