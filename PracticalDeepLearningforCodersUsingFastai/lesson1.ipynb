{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51df0f29",
   "metadata": {},
   "source": [
    "This is first notebook with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51729ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS #DuckDuckGo has changed the api so we need to update \n",
    "from fastcore.all import *\n",
    "\n",
    "def search_images(keywords, max_images=200): \n",
    "    return L(DDGS().images(keywords, max_results=max_images)).itemgot('image')\n",
    "import time, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817253b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images6.fanpop.com/image/photos/40700000/Colourful-Bird-birds-40741713-1280-960.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = search_images('bird photos', max_images=1)\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdownload import download_url\n",
    "dest = 'bird.jpg'\n",
    "download_url(urls[0], dest, show_progress=False)\n",
    "\n",
    "from fastai.vision.all import *\n",
    "im = Image.open(dest)\n",
    "im.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3d7e8",
   "metadata": {},
   "source": [
    "Now let's do the same with \"forest photos\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\n",
    "Image.open('forest.jpg').to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b69c3e",
   "metadata": {},
   "source": [
    "Our searches seem to be giving reasonable results, so let's grab a few examples of each of \"bird\" and \"forest\" photos, and save each group of photos to a different folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98452e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = 'forest','bird'\n",
    "path = Path('bird_or_not')\n",
    "\n",
    "for o in searches:\n",
    "    dest = (path/o)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    download_images(dest, urls=search_images(f'{o} photo'))\n",
    "    time.sleep(5)\n",
    "    resize_images(path/o, max_size=400, dest=path/o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671b0a8",
   "metadata": {},
   "source": [
    "Step 2: Train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93106148",
   "metadata": {},
   "source": [
    "Some photos might not download correctly which could cause our model training to fail, so we'll remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ddcce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed = verify_images(get_image_files(path))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3fac9",
   "metadata": {},
   "source": [
    "To train a model, we'll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model -- not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=[Resize(192, method='squish')]\n",
    ").dataloaders(path, bs=32)\n",
    "\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74678dbc",
   "metadata": {},
   "source": [
    "Here what each of the DataBlock parameters means:\n",
    "\n",
    "blocks=(ImageBlock, CategoryBlock),\n",
    "- The inputs to our model are images, and the outputs are categories (in this case, \"bird\" or \"forest\").\n",
    "\n",
    "get_items=get_image_files,\n",
    "- To find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\n",
    "\n",
    "splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "- Split the data into training and validation sets randomly, using 20% of the data for the validation set.\n",
    "\n",
    "get_y=parent_label,\n",
    "- The labels (y values) is the name of the parent of each file (i.e. the name of the folder they're in, which will be bird or forest).\n",
    "\n",
    "item_tfms=[Resize(192, method='squish')]\n",
    "- Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a922c",
   "metadata": {},
   "source": [
    "Now we're ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n",
    "\n",
    "fastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a8133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\VeeneetKumar/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 24.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.914138</td>\n",
       "      <td>0.354116</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.154227</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.105221</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af961611",
   "metadata": {},
   "source": [
    "\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the pretrained model), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in imagenet, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it's important, check out the free fast.ai course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c9dec",
   "metadata": {},
   "source": [
    "Step 3: Use our model (and build your own!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd14dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a: bird.\n",
      "Probability it's a bird: 1.0000\n"
     ]
    }
   ],
   "source": [
    "is_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\n",
    "print(f\"This is a: {is_bird}.\")\n",
    "print(f\"Probability it's a bird: {probs[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de299a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
